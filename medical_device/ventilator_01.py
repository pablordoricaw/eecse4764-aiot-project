import argparse
import atexit
import datetime
import json
import logging
import logging.config
import logging.handlers
import os

from typing import override

###############################################################################
# Logging Utils
###############################################################################

logger = None


class JsonLineFormatter(logging.Formatter):
    def __init__(self, *, fmt_keys: dict[str, str] | None = None):
        super().__init__()
        self.fmt_keys = fmt_keys if fmt_keys is not None else {}

    @override
    def format(self, record: logging.LogRecord) -> str:
        always_fields = {
            "timestamp": datetime.datetime.fromtimestamp(
                record.created, tz=datetime.timezone.utc
            ).isoformat(),
        }
        if record.exc_info:
            always_fields["exc_info"] = self.formatException(record.exc_info)

        if record.stack_info:
            always_fields["stack_info"] = self.formatException(record.stack_info)

        message = {
            key: msg_val
            if (msg_val := always_fields.pop(val, None)) is not None
            else getattr(record, val)
            for key, val in self.fmt_keys.items()
        }
        message.update(always_fields)

        return json.dumps(message, ensure_ascii=False)


class NonErrorFilter(logging.Filter):
    @override
    def filter(self, record: logging.LogRecord) -> bool | logging.LogRecord:
        return record.levelno <= logging.INFO


logging_config = {
    "version": 1,
    "disable_existing_loggers": False,
    "formatters": {
        "simple": {
            "format": "[%(asctime)s][%(levelname)s]: %(message)s",
            "datefmt": "%Y-%m-%dT%H:%M:%S%z",
        },
        "jsonl": {
            "()": f"{__name__}.JsonLineFormatter",
            "fmt_keys": {
                "level": "levelname",
                "message": "message",
                "timestamp": "timestamp",
                "logger": "name",
                "module": "module",
                "function": "funcName",
                "line": "lineno",
                "thread_name": "threadName",
            },
        },
    },
    "filters": {"no_errors": {"()": f"{__name__}.NonErrorFilter"}},
    "handlers": {
        "stdout": {
            "class": "logging.StreamHandler",
            "formatter": "simple",
            "filters": ["no_errors"],
            "stream": "ext://sys.stdout",
        },
        "stderr": {
            "class": "logging.StreamHandler",
            "formatter": "simple",
            "stream": "ext://sys.stderr",
            "level": "WARNING",
        },
        "jsonl_file": {
            "class": "logging.handlers.RotatingFileHandler",
            "formatter": "jsonl",
            "filename": "logs/ventilator.log.jsonl",
            "maxBytes": 10_000,  # rotate after X many bytes
            "backupCount": 50,  # keep X many old files
            "encoding": "utf-8",
        },
        "queue_handler": {
            "class": "logging.handlers.QueueHandler",
            # Python 3.12+ dictConfig support for QueueHandler+QueueListener:
            # this list is the *target* handlers for the listener
            "handlers": ["stdout", "stderr", "jsonl_file"],
            "respect_handler_level": True,
        },
    },
    "loggers": {"root": {"level": "DEBUG", "handlers": ["queue_handler"]}},
}


def jsonl_file_namer(default_name: str) -> str:
    """
    Return a new log filename that inserts a creation timestamp before the
    `.log.jsonl` suffix for rotated JSONL log files.

    The `default_name` argument is the original rotated filename generated by
    the logging handler, which is the configured base filename from the
    logging_config above with a numeric suffix appended,

    i.e., `logs/ventilator.log.jsonl.1`.
    """
    dirname, basename = os.path.split(default_name)
    parts = basename.split(".")

    if len(parts) < 4:
        return default_name

    base = parts[0]  # 'ventilator'
    rest = ".".join(parts[1:-1])  # 'log.jsonl'

    ts = datetime.datetime.now().strftime("%Y%m%dT%H%M%S")
    new_basename = f"{base}.{ts}.{rest}"
    return os.path.join(dirname, new_basename)


def setup_logging(config=logging_config) -> logging.Logger:
    """
    Initialize and configure logging.

    Applies the given logging configuration, sets up a queue-based handler for
    non-blocking, thread-safe logging to stdout, stderr, and disk in JSONL
    format and registers a shutdown hook to stop the queue listener at process
    exit. Call this once near the start of your main program before issuing any
    logging calls.

    Args:
        config (dict, optional): Logging configuration dictionary in
            logging.config.dictConfig format. Defaults to `logging_config`,
            which routes INFO and lower to stdout and WARNING and above to
            stderr.

    """
    logger = logging.getLogger("ventilator-01")

    ts = datetime.datetime.now().strftime("%Y%m%dT%H%M%S")
    base_name = f"ventilator.{ts}.log.jsonl"
    json_handler_cfg = config["handlers"]["jsonl_file"]
    dirname, _ = os.path.split(json_handler_cfg["filename"])
    if dirname:
        os.makedirs(dirname, exist_ok=True)

    json_handler_cfg["filename"] = os.path.join(dirname, base_name)

    logging.config.dictConfig(logging_config)
    queue_handler = logging.getHandlerByName("queue_handler")

    if queue_handler is not None and hasattr(queue_handler, "listener"):
        for h in queue_handler.listener.handlers:
            if isinstance(h, logging.handlers.RotatingFileHandler):
                h.namer = jsonl_file_namer
        queue_handler.listener.start()
        atexit.register(queue_handler.listener.stop)
    return logger


###############################################################################
# Ventilator
###############################################################################


def setup_argparser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--log-level",
        default="INFO",
        choices=["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"],
        help="Set the logging level (default: INFO)",
    )
    # TODO: Add CLI arguments that will determine the ventilator functionality
    return parser


def main():
    parser = setup_argparser()
    args = parser.parse_args()

    global logger
    logger = setup_logging()
    logger.setLevel(args.log_level)

    # TODO: Simulate ventilator functionality

    logger.info("info message")
    logger.warning("warning message")
    logger.error("error message")
    logger.critical("critical message")

    try:
        1 / 0
    except ZeroDivisionError:
        logger.exception("exception message")


if __name__ == "__main__":
    main()
